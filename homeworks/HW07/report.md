# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (12000, 9)
- Признаки: числовые (int64 и float64)
- Пропуски: нет
- "Подлости" датасета: разные масштабы, выбросы

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (8000, 4)
- Признаки: числовые (int64 и float64)
- Пропуски: нет
- "Подлости" датасета: разные масштабы, выбросы, лишние (шумовые) признаки

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: (15000, 5)
- Признаки: числовые (int64 и float64)
- Пропуски: нет
- "Подлости" датасета: избыточные признаки, шумовые признаки, низкая плотность

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг: scaling
- Поиск гиперпараметров:
  - k: от 2 до 12, eps: [0.15, 0.20, 0.25, 0.30], min_samples: [5, 8, 12]
  - При выборе лучшего: основной упор на silhouette (чем выше, тем лучше) + для DBSCAN учет визуального качества кластеризации и количество шума
- Метрики: silhouette + Davies-Bouldin + Calinski-Harabasz (для DBSCAN точки, помеченные как шум (-1), исключались из анализа)
- Визуализация: PCA(2D)

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

- KMeans (поиск `k`, фиксировали `random_state`, `n_init`)
- DBSCAN (`eps`, `min_samples`, доля шума)

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: k-means при k = 2
- Метрики (silhouette / DB / CH): 
  - 'silhouette': 0.5216395622404242,
  - 'davies_bouldin': 0.6853295219054457,
  - 'calinski_harabasz': 11786.954622671532
- Это решение выглядит разумным, так как после масштабирования признаков k-means эффективно выделяет устойчивую и интерпретируемую кластерную структуру, в то время как DBSCAN страдает от разной плотности кластеров и чувствителен к выбросам

### 4.2 Dataset B

- Лучший метод и параметры: k-means при k = 2
- Метрики (silhouette / DB / CH): 
  - 'silhouette': 0.3068610017701601,
  - 'davies_bouldin': 1.3234721699867644,
  - 'calinski_harabasz': 3573.3933329348392
- Это решение выглядит разумным, так как  после масштабирования k-means устойчиво выявляет кластерную структуру в информативных признаках (x1, x2), в то время как DBSCAN страдает от сильного шума, выбросов и неравномерной плотности, что снижает его качество

### 4.3 Dataset C

- Лучший метод и параметры: k-means при k = 3
- Метрики (silhouette / DB / CH): 
  - 'silhouette': 0.3155447003782518,
  - 'davies_bouldin': 1.1577256320598661,
  - 'calinski_harabasz': 6957.162639510167
- Это решение выглядит разумным, так как после масштабирования k-means устойчив к линейной избыточности и неинформативному шуму, успешно выделяя основную кластерную структуру, в то время как DBSCAN получает результаты хуже из-за снижения плотности и искажения расстояний, вызванных некорректными признаками

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- В данном случае K-Means показал стабильно хорошие результаты, однако он может ломаться на данных при существовании шумовых или сильно разномасштабных признаков, поскольку чувствителен к масштабу признаков
- DBSCAN и иерархическая кластеризация выигрывают на сложных данных, так как DBSCAN не требует задания числа кластеров и устойчив к выбросам, а иерархическая кластеризация хорошо работает при естественной иерархии в данных
- Сильнее всего на результат повлияло масштабирование: без него алгоритмы фокусировались бы на признаках с большим размахом, игнорируя истинную структуру, в то время как выбросы и шумовые признаки дополнительно ухудшали качество

### 5.2 Устойчивость (обязательно для одного датасета)

- 5 запусков K-Means по разным seed (1,2,3,4,5) на датасете 1
- При многократных запусках K-Means с разными random_state метрики качества остались идентичными, а ARI между всеми парами разбиений равен 1.0. Это означает, что все запуски дали абсолютно одинаковые кластерные метки
- Вывод: устойчиво, так как ARI = 1.0 - это максимальное значение, указывающее на полное совпадение разбиений. Это говорит о том, что алгоритм не зависит от инициализации и K-Means стабильно воспроизводит одно и то же решение

### 5.3 Интерпретация кластеров

- Как вы интерпретировали кластеры:
  - Кластеры интерпретировались через профили средних значений признаков
- Кластеры в каждом датасете четко различаются по средним значениям признаков, что позволяет им давать содержательную интерпретацию - например, «кластер с высоким f02 и низким f04» или «группа объектов с экстремальными значениями z_noise». K-Means выделял устойчивые группы с ярко выраженными профилями, тогда как DBSCAN часто формировал дополнительные кластеры из шумовых или аномальных точек (например, с выбросами по z_noise). В целом, интерпретация подтвердила, что лучшие кластеризации соответствуют структуре данных: компактные и с логичными различиями между группами

## 6. Conclusion

4-8 коротких тезисов: чему научились про кластеризацию, метрики и корректный протокол unsupervised-эксперимента.

- Качество кластеризации нельзя оценивать только по чему-то одному, нужны визуализация и внутренние метрики
- Масштабирование признаков очень важно, особенно при несболансированных данных
- Подбор гиперпараметров (k, eps, min_samples) важно осуществлять не случайным образом, а на основе тестирования и анализа 
- Silhouette чувствителен к шуму и числу кластеров
- Интерпретация кластеров через профили признаков превращает абстрактные метки в содержательные группы
- В unsupervised-задачах нужен четкий протокол: фиксация случайных состояний, предобработка, кластеризация, оценка и интерпретация 




